{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate choicefile & qivarfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantize\n",
    "# copy from makepathweightfiles/makepathweightfiles.ipynb\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "def quantize_to_multiple_of_1_64(x,factor):\n",
    "    return round(x * factor) / factor\n",
    "\n",
    "def quantize_and_adjust_with_indices(indexed_values,factor,isprint=False):\n",
    "    if isprint: print(indexed_values)\n",
    "    # Quantize each value\n",
    "    quantized_values = [(i, quantize_to_multiple_of_1_64(v,factor)) for i, v in indexed_values]\n",
    "    if isprint: print(quantized_values)\n",
    "    \n",
    "    # Calculate the current sum\n",
    "    current_sum = sum(v for _, v in quantized_values)\n",
    "    \n",
    "    # Calculate the difference between the sum and 1\n",
    "    difference = current_sum - 1\n",
    "    if isprint: print(f\"currsum={current_sum}, difference={difference}\")\n",
    "\n",
    "    random_values = [(v, random.random()) for v in quantized_values]\n",
    "    if isprint: print(random_values)\n",
    "    \n",
    "    if difference != 0:\n",
    "        if difference > 0:\n",
    "            # Sort indices by quantized values to adjust the largest values first\n",
    "            sorted_random = sorted(random_values, key=lambda x: (x[0][1],x[1]), reverse=True)\n",
    "            # sorted_quantized = sorted(quantized_values, key=lambda x: x[1], reverse=True)\n",
    "            sorted_quantized = [v for v,_ in sorted_random]\n",
    "            if isprint: print(sorted_random)\n",
    "            if isprint: print(sorted_quantized)\n",
    "            \n",
    "            while difference !=0:\n",
    "                for i, value in sorted_quantized:\n",
    "                    if difference == 0:\n",
    "                        break\n",
    "                    # Calculate adjustment\n",
    "                    # adjustment = min(difference, value % (1 / factor))\n",
    "                    # adjustment = difference\n",
    "                    new_value = value - 1.0/factor\n",
    "                    \n",
    "                    # Update the quantized values\n",
    "                    quantized_values = [(idx, new_value if idx == i else v) for idx, v in quantized_values]\n",
    "                    difference -= 1.0/factor\n",
    "                \n",
    "        else:\n",
    "            # If the difference is negative (i.e., sum is less than 1), we need to increase values\n",
    "            # sorted_quantized = sorted(quantized_values, key=lambda x: x[1])\n",
    "            sorted_random = sorted(random_values, key=lambda x: (x[0][1],x[1]))\n",
    "            # sorted_quantized = sorted(quantized_values, key=lambda x: x[1], reverse=True)\n",
    "            sorted_quantized = [v for v,_ in sorted_random]\n",
    "            \n",
    "            while difference != 0:\n",
    "                for i, value in sorted_quantized:\n",
    "                    if difference == 0:\n",
    "                        break\n",
    "                    # Calculate adjustment\n",
    "                    # adjustment = min(-difference, (1 / factor) - (value % (1 / factor)))\n",
    "                    # adjustment = -difference\n",
    "                    new_value = value + 1.0/factor\n",
    "                    \n",
    "                    # Update the quantized values\n",
    "                    quantized_values = [(idx, new_value if idx == i else v) for idx, v in quantized_values]\n",
    "                    difference += 1.0/factor\n",
    "    \n",
    "    # Return the list sorted by original indices\n",
    "    # return [v for i, v in sorted(quantized_values)]\n",
    "    if isprint: print(quantized_values)\n",
    "    return quantized_values\n",
    "\n",
    "def check(qvarfile, numsw):\n",
    "    # check qvarfile\n",
    "    checkweightarr = list()\n",
    "    for i in range(numsw):\n",
    "        checkweightarr.append(list())\n",
    "        for j in range(numsw):\n",
    "            checkweightarr[i].append(0)\n",
    "    with open(qvarfile,'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            tokens = line.split(',')\n",
    "            fromsw = int(tokens[0])\n",
    "            tosw = int(tokens[1])\n",
    "            pid = int(tokens[2])\n",
    "            weight = float(tokens[3])\n",
    "            checkweightarr[fromsw][tosw] += weight\n",
    "\n",
    "    for fromsw in range(numsw):\n",
    "        for tosw in range(numsw):\n",
    "            if checkweightarr[fromsw][tosw]!=0 and checkweightarr[fromsw][tosw]!=1:\n",
    "                print(f\"from {fromsw} to {tosw}: weight={checkweightarr[fromsw][tosw]}\")\n",
    "\n",
    "def quantize(varfile, qvarfile, factor, numsw):\n",
    "    with open(varfile,'r') as f:\n",
    "        lines = f.readlines()[1:]\n",
    "\n",
    "    valuearr = list()\n",
    "    weightarr = list()\n",
    "    qweightarr = list()\n",
    "    for i in range(numsw):\n",
    "        valuearr.append(list())\n",
    "        weightarr.append(list())\n",
    "        qweightarr.append(list())\n",
    "        for j in range(numsw):\n",
    "            valuearr[i].append(list())\n",
    "            weightarr[i].append(list())\n",
    "            qweightarr[i].append(list()) \n",
    "\n",
    "    for line in lines:\n",
    "        tokens = line.split(',')\n",
    "        varname = tokens[0]\n",
    "        vartokens = varname.split('_')\n",
    "        fromsw = int(vartokens[0])\n",
    "        tosw = int(vartokens[1])\n",
    "        pid = int(vartokens[2])\n",
    "        value = float(tokens[1])\n",
    "        valuearr[fromsw][tosw].append([pid,value])\n",
    "        weightarr[fromsw][tosw].append([pid,value])\n",
    "\n",
    "    for fromsw in range(numsw):\n",
    "        for tosw in range(numsw):\n",
    "            if len(valuearr[fromsw][tosw])>0:\n",
    "                valuesum = 0\n",
    "                for _,value in valuearr[fromsw][tosw]:\n",
    "                    valuesum += value\n",
    "                valuetoweight = 1.0/valuesum\n",
    "                for ipv,pv in enumerate(weightarr[fromsw][tosw]):\n",
    "                    weightarr[fromsw][tosw][ipv][1] = pv[1] * valuetoweight\n",
    "\n",
    "    for fromsw in range(numsw):\n",
    "        for tosw in range(numsw):\n",
    "            if len(weightarr[fromsw][tosw])>0:\n",
    "                qweightarr[fromsw][tosw] = quantize_and_adjust_with_indices(weightarr[fromsw][tosw],factor)\n",
    "\n",
    "    with open(qvarfile,'w') as f:\n",
    "        for fromsw in range(numsw):\n",
    "            for tosw in range(numsw):\n",
    "                if len(qweightarr[fromsw][tosw])>0:\n",
    "                    for pid,weight in qweightarr[fromsw][tosw]:\n",
    "                        if weight>0:\n",
    "                            f.write(f\"{fromsw},{tosw},{pid},{weight}\\n\")\n",
    "\n",
    "    check(qvarfile, numsw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# cluster_c\n",
    "H=2\n",
    "factor=64\n",
    "numsw=80\n",
    "resultfile = f\"/home/annzhou/DRing/src/emp/datacentre/computerouting2/resultfiles/result_dring_0_0_cluster_c_2_0\"\n",
    "choicedict = dict()\n",
    "for i in range(24,48):\n",
    "    choicedict[i] = 0\n",
    "with open(resultfile,'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        tokens = line.split(',')\n",
    "        myH = int(tokens[0])\n",
    "        if myH == H:\n",
    "            solveinterval = int(tokens[1])\n",
    "            # routing = tokens[3]\n",
    "            computeinterval = int(tokens[4])\n",
    "            choicedict[solveinterval] = computeinterval\n",
    "\n",
    "for interval in range(24,48):\n",
    "    myfile = f\"/home/annzhou/DRing/src/emp/datacentre/qivarfiles/qivar_dring_0_0_cluster_c_{interval}_su3_2_0\"\n",
    "    if interval in range(30,42):\n",
    "        # just copy\n",
    "        copyfromfile = f\"/home/annzhou/DRing/src/emp/datacentre/qivarfiles/routing_cluster_c/qivar_dring_0_0_cluster_c_{interval}_su3_2_0\"\n",
    "        shutil.copy(copyfromfile, myfile)\n",
    "    else:\n",
    "        # need to quantize\n",
    "        ivarfile = f\"/home/annzhou/DRing/src/emp/datacentre/qivarfiles/routing_cluster_c/ivar_dring_0_0_su3_cluster_c_{choicedict[interval]}_2_0\"\n",
    "        quantize(ivarfile, myfile, factor, numsw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate conffiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trafficname = \"cluster_c\"\n",
    "multstrarr1 = [\"0 19 100\",\"0 38 100\",\"0 57 100\",\"0 75 100\",\"0 94 100\",\"1 13 100\",\"1 32 100\",\"1 51 100\",\"1 70 100\"]\n",
    "multnamearr1 = range(10,91,10)\n",
    "sseedarr = range(1,6)\n",
    "\n",
    "conffile = f\"/home/annzhou/DRing/src/emp/datacentre/experiments/routing2/{trafficname}.conf\"\n",
    "make_leafspine = \"MAKE\"\n",
    "make_dring = \"MAKE\"\n",
    "with open(conffile,'w') as f:\n",
    "    for imultstr,multstr in enumerate(multstrarr1):\n",
    "        for sseed in sseedarr:\n",
    "            multname = multnamearr1[imultstr]\n",
    "            # f.write(f\"./run.sh LEAFSPINE {make_leafspine} 80 3072 64 leafspine_{trafficname} NEW_WISC null {multstr} 24 48 0 0 0 0 ecmp 0 {trafficname} {sseed} netpathfiles/netpath_ecmp_leafspine.txt qvarfiles/qvar_leafspine_0_0_ecmp_64 64 50 150 200 0 0 > m_leafspine_{trafficname}_{multname}_{sseed}.log\\n\")\n",
    "            make_leafspine = \"NOMAKE\"\n",
    "            f.write(f\"./run.sh RRG {make_dring} 80 2988 64 dring_{trafficname} NEW_WISC graphfiles/ring_supergraph/double_ring/instance1_80_64.edgelist {multstr} 24 48 0 0 0 0 null 0 {trafficname} serverfiles/dring_2988_80_64 {sseed} null null 64 50 150 200 0 0 > m_dring_{trafficname}_{multname}_{sseed}.log\\n\")\n",
    "            make_dring = \"NOMAKE\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
