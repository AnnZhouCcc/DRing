{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "multnamearr = [10,20]\n",
    "multstrarr = [\"1 7 16\",\"2 7 8\"]\n",
    "sseedarr = [1]\n",
    "trafficfiles = [\"flowfiles/c2s_64_4_1_7_16_0\",\"flowfiles/c2s_64_4_2_7_8_0\"]\n",
    "pwfilesuffixarr = [\"c2s_64_4_0_1_7_16_2_0_64\",\"c2s_64_4_0_2_7_8_2_0_64\"]\n",
    "\n",
    "with open(f\"/home/annzhou/DRing/src/emp/datacentre/experiments/linkfailure2/whatload.conf\",'w') as f:\n",
    "    for imultname,multname in enumerate(multnamearr):\n",
    "        multstr = multstrarr[imultname]\n",
    "        trafficfile = trafficfiles[imultname]\n",
    "        pwfilesuffix = pwfilesuffixarr[imultname]\n",
    "\n",
    "        rtname = \"ecmp\"\n",
    "        rt1 = \"ecmp\"\n",
    "        rt2 = 0\n",
    "        pwname = \"equal\"\n",
    "        pwfile = f\"qvarfiles/qvar_leafspine_0_0_{rtname}_64\"\n",
    "        make_leafspine = \"MAKE\"\n",
    "        for sseed in sseedarr:\n",
    "            f.write(f\"./run.sh LEAFSPINE {make_leafspine} 80 3072 64 leafspine_nf NEW_FILE null {multstr} 0 0 0 0 0 0 {rt1} {rt2} {trafficfile} {sseed} netpathfiles/netpath_{rtname}_leafspine.txt {pwfile} 64 50 150 200 0 0 > m_whatrouting_leafspine_{rtname}_nf_{pwname}_{multname}.log\\n\")\n",
    "            make_leafspine = \"NOMAKE\"\n",
    "\n",
    "        rtname = \"32disjoint\"\n",
    "        rt1 = \"kdisjoint\"\n",
    "        rt2 = 32\n",
    "        pwname = \"thisweight\"\n",
    "        make_dring = \"MAKE\"\n",
    "        pwfile = f\"qvarfiles/qvar_dring_0_0_{rtname}_{pwfilesuffix}\"\n",
    "        for sseed in sseedarr:\n",
    "            f.write(f\"./run.sh RRG {make_dring} 80 2988 64 dring_nf NEW_FILE graphfiles/ring_supergraph/double_ring/instance1_80_64.edgelist {multstr} 0 0 0 0 0 0 {rt1} {rt2} {trafficfile} {sseed} netpathfiles/netpath_{rtname}_dring.txt {pwfile} 64 50 150 200 0 0 > m_whatrouting_dring_{rtname}_nf_{pwname}_{multname}.log\\n\")\n",
    "            make_dring = \"NOMAKE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate sumfile & picklefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "homedir = \"/home/annzhou\"\n",
    "conffile = f\"{homedir}/DRing/src/emp/datacentre/experiments/linkfailure2/whatload.conf\"\n",
    "sumfile = f\"{homedir}/DRing/src/emp/datacentre/experiments/linkfailure2/whatload.txt\"\n",
    "datadict = dict()\n",
    "with open(conffile,'r') as f:\n",
    "    with open(sumfile,'a') as sumf:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            tokens = line.split()\n",
    "            logfile = tokens[31]\n",
    "            sizelist = list()\n",
    "            durationlist = list()\n",
    "            startlist = list()\n",
    "            with open(f\"{homedir}/DRing/src/emp/datacentre/{logfile}\",'r') as logf:\n",
    "                print(logfile)\n",
    "                loglines = logf.readlines()\n",
    "                for logline in loglines:\n",
    "                    logtokens = logline.split()\n",
    "                    if logtokens[0] == \"FCT\":\n",
    "                        durationlist.append(float(logtokens[2]))\n",
    "                        sizelist.append(int(logtokens[1]))\n",
    "                        startlist.append(float(logtokens[3]))\n",
    "            datadict[logfile] = [durationlist,sizelist,startlist]\n",
    "            durationlist.sort()\n",
    "            sumf.write(f\"{logfile}\\t{sum(durationlist)/len(durationlist)}\\t{durationlist[int(len(durationlist)*0.5)]}\\t{durationlist[int(len(durationlist)*0.99)]}\\t{durationlist[int(len(durationlist)*0.9999)]}\\n\")\n",
    "\n",
    "    with open(f'/home/annzhou/DRing/src/emp/datacentre/experiments/linkfailure2/whatload.pickle', 'wb') as handle:\n",
    "        pickle.dump(datadict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "delete logfiles, run, _log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "homedir = \"/home/annzhou\"\n",
    "conffile = f\"{homedir}/DRing/src/emp/datacentre/experiments/linkfailure2/whatload.conf\"\n",
    "with open(conffile,'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        tokens = line.split()\n",
    "        logfile = tokens[31]\n",
    "        os.remove(f\"{homedir}/DRing/src/emp/datacentre/{logfile}\")\n",
    "\n",
    "dringdir = f\"{homedir}/DRing/src/emp/datacentre\"\n",
    "for filedir in os.listdir(dringdir):\n",
    "    if os.path.isfile(os.path.join(dringdir, filedir)):\n",
    "        tokens = filedir.split(\"_\")\n",
    "        if (tokens[0]==\"rrg\" or tokens[0]==\"leafspine\") and tokens[1]==\"log\":\n",
    "            print(filedir)\n",
    "            os.remove(f\"{homedir}/DRing/src/emp/datacentre/{filedir}\")\n",
    "        if (tokens[-1]==\"run\") and ((tokens[0]==\"leafspine\" and tokens[1]==\"leafspine\") or (tokens[0]==\"rrg\" and (tokens[1]==\"rrg\" or tokens[1]==\"dring\"))):\n",
    "            print(filedir)\n",
    "            os.remove(f\"{homedir}/DRing/src/emp/datacentre/{filedir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
