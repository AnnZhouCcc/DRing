{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "solve\n",
    "inspired by https://github.com/AnnZhouCcc/topobench/blob/master/lpmaker/graphs/Graph.java#L1382"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "graphname = \"dring\"\n",
    "routingname = \"ecmp\"\n",
    "pwname = \"\"\n",
    "numsw = 80\n",
    "numport = 64\n",
    "numserver = 2988\n",
    "numfaillink = 0\n",
    "numlink = 2132\n",
    "fseed = 0\n",
    "homedir = \"/home/annzhou\"\n",
    "\n",
    "c=64\n",
    "s=4\n",
    "multstr=\"4_5_16\"\n",
    "tseed = 0\n",
    "trafficname = f\"c2s_{c}_{s}_{tseed}_{multstr}\"\n",
    "\n",
    "method = 2\n",
    "crossover = 0\n",
    "factor = 64\n",
    "\n",
    "\n",
    "flowfile = f\"{homedir}/DRing/src/emp/datacentre/flowfiles/c2s_{c}_{s}_{multstr}_{tseed}\"\n",
    "\n",
    "if graphname==\"dring\" or graphname==\"rrg\":\n",
    "    netpathfile = f\"{homedir}/DRing/src/emp/datacentre/netpathfiles/netpath_{routingname}_{graphname}.txt\"\n",
    "else:\n",
    "    print(\"ERROR: leafspine does not need to compute path weight\")\n",
    "\n",
    "if graphname==\"dring\":\n",
    "    graphfile = f\"{homedir}/DRing/src/emp/datacentre/graphfiles/ring_supergraph/double_ring/instance1_{numsw}_{numport}.edgelist\"\n",
    "elif graphname==\"rrg\":\n",
    "    graphfile = f\"{homedir}/DRing/src/emp/datacentre/graphfiles/ring_supergraph/rrg/instance1_{numsw}_{numport}.edgelist\"\n",
    "else:\n",
    "    print(\"ERROR: leafspine does not need to compute path weight\")\n",
    "\n",
    "linkfailurefile = f\"{homedir}/DRing/src/emp/datacentre/linkfailurefiles/{graphname}_{numlink}_{numfaillink}_{fseed}\"\n",
    "\n",
    "serverfile = f\"{homedir}/DRing/src/emp/datacentre/serverfiles/{graphname}_{numserver}_{numsw}_{numport}\"\n",
    "\n",
    "tag = f\"{graphname}_{numfaillink}_{fseed}_{routingname}_{trafficname}_{method}_{crossover}_{factor}\"\n",
    "varfile = f\"{homedir}/DRing/src/emp/datacentre/qvarfiles/var_{tag}\"\n",
    "qvarfile = f\"{homedir}/DRing/src/emp/datacentre/qvarfiles/qvar_{tag}\"\n",
    "modelfile = f\"{homedir}/DRing/src/emp/datacentre/makepathweightfiles/model.lp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirprefix = f\"{homedir}/DRing/src/emp/datacentre\"\n",
    "# netpathfile = f\"{dirprefix}/netpathfiles/node3.txt\"\n",
    "# graphfile = f\"{dirprefix}/graphfiles/node3.edgelist\"\n",
    "# serverfile = f\"{dirprefix}/serverfiles/node3\"\n",
    "# flowfile = f\"{dirprefix}/flowfiles/node3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read netpathfile\n",
    "netpath = list()\n",
    "for i in range(numsw):\n",
    "    netpath.append(list())\n",
    "    for j in range(numsw):\n",
    "        netpath[i].append(list())\n",
    "with open(netpathfile,'r') as f:\n",
    "    lines = f.readlines()\n",
    "    # produce\n",
    "    fromsw = 0\n",
    "    tosw = 0\n",
    "    for line in lines:\n",
    "        if \"->\" not in line:\n",
    "            tokens = line.split()\n",
    "            fromsw = int(tokens[0])\n",
    "            tosw = int(tokens[1])\n",
    "        else:\n",
    "            path = [fromsw]\n",
    "            tokens = line.split()\n",
    "            for token in tokens:\n",
    "                hops = token.split(\"->\")\n",
    "                path.append(int(hops[1]))\n",
    "            netpath[fromsw][tosw].append(path)\n",
    "\n",
    "    # check\n",
    "    for line in lines:\n",
    "        if \"->\" not in line:\n",
    "            tokens = line.split()\n",
    "            fromsw = int(tokens[0])\n",
    "            tosw = int(tokens[1])\n",
    "            numpaths = int(tokens[2])\n",
    "            if len(netpath[fromsw][tosw])!=numpaths:\n",
    "                print(f\"ERROR: netpath is wrong, fromsw={fromsw}, tosw={tosw}, numpaths from file={numpaths}, numpaths from array={len(netpath[fromsw][tosw])}\")\n",
    "\n",
    "# read graphfile\n",
    "link = list()\n",
    "for i in range(numsw):\n",
    "    link.append(list())\n",
    "    for j in range(numsw):\n",
    "        link[i].append(0)\n",
    "with open(graphfile,'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        tokens = line.split(\"->\")\n",
    "        fromsw = int(tokens[0])\n",
    "        tosw = int(tokens[1])\n",
    "        link[fromsw][tosw] = 1\n",
    "        link[tosw][fromsw] = 1\n",
    "\n",
    "# read linkfailurefile (if needed)\n",
    "if numfaillink > 0:\n",
    "    with open(linkfailurefile,'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            tokens = line.split()\n",
    "            fromsw = int(tokens[0])\n",
    "            tosw = int(tokens[1])\n",
    "            if link[fromsw][tosw] != 1:\n",
    "                print(f\"ERROR: should have a link from {fromsw} to {tosw} but not\")\n",
    "            else:\n",
    "                link[fromsw][tosw] /= 2\n",
    "\n",
    "# read serverfile\n",
    "serverdict = dict()\n",
    "with open(serverfile,'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        tokens = line.split(',')\n",
    "        serverdict[int(tokens[0])] = int(tokens[1])\n",
    "\n",
    "# read flowfile\n",
    "traffic = list()\n",
    "for i in range(numsw):\n",
    "    traffic.append(list())\n",
    "    for j in range(numsw):\n",
    "        traffic[i].append(0)\n",
    "with open(flowfile,'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        tokens = line.split(\",\")\n",
    "        fromsvr = int(tokens[0])\n",
    "        tosvr = int(tokens[1])\n",
    "        if fromsvr>=numserver or tosvr>=numserver: continue\n",
    "        fromsw = serverdict[fromsvr]\n",
    "        tosw = serverdict[tosvr]\n",
    "        if fromsw == tosw: continue\n",
    "        flowbytes = int(tokens[2])\n",
    "        traffic[fromsw][tosw] += flowbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precompute\n",
    "flowsvialink = list()\n",
    "for i in range(numsw):\n",
    "    flowsvialink.append(list())\n",
    "    for j in range(numsw):\n",
    "        flowsvialink[i].append(list())\n",
    "for fromsw in range(numsw):\n",
    "    for tosw in range(numsw):\n",
    "        if traffic[fromsw][tosw] > 0:\n",
    "            for pid,path in enumerate(netpath[fromsw][tosw]):\n",
    "                fidpidstr = f\"{fromsw},{tosw},{pid}\"\n",
    "                prevhop = fromsw\n",
    "                for hop in path[1:]:\n",
    "                    flowsvialink[prevhop][hop].append(fidpidstr)\n",
    "                    prevhop = hop\n",
    "\n",
    "for fromsw in range(numsw):\n",
    "    for tosw in range(numsw):\n",
    "        traffic[fromsw][tosw] /= 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Method to value 2\n",
      "Set parameter Crossover to value 0\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (linux64 - \"Ubuntu 20.04.6 LTS\")\n",
      "\n",
      "CPU model: Intel(R) Xeon(R) CPU E5-2630 v4 @ 2.20GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 20 physical cores, 40 logical processors, using up to 20 threads\n",
      "\n",
      "Optimize a model with 2370 rows, 22321 columns and 86140 nonzeros\n",
      "Model fingerprint: 0x8a3a182f\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+03]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Presolve removed 316 rows and 212 columns\n",
      "Presolve time: 0.06s\n",
      "Presolved: 2054 rows, 22109 columns, 85612 nonzeros\n",
      "Ordering time: 0.02s\n",
      "\n",
      "Barrier statistics:\n",
      " Dense cols : 1\n",
      " AA' NZ     : 5.951e+04\n",
      " Factor NZ  : 2.038e+05 (roughly 11 MB of memory)\n",
      " Factor Ops : 3.596e+07 (less than 1 second per iteration)\n",
      " Threads    : 20\n",
      "\n",
      "                  Objective                Residual\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\n",
      "   0   1.18712761e-02 -1.39928573e-04  4.60e+01 2.90e-04  7.82e-02     0s\n",
      "   1   4.37908791e-05  6.24140458e+00  2.47e+01 6.52e-02  4.29e-02     0s\n",
      "   2   1.98789059e-03  1.16518765e+01  2.23e+01 2.84e-02  3.67e-02     0s\n",
      "   3   4.22812320e-04  1.23448279e+01  6.04e+00 0.00e+00  1.03e-02     0s\n",
      "   4   1.66638218e-04  7.84386768e+00  3.54e+00 0.00e+00  5.77e-03     0s\n",
      "   5   8.46341985e-05  5.76529199e+00  2.19e+00 0.00e+00  3.60e-03     0s\n",
      "   6   3.09463930e-05  4.24929154e+00  1.13e+00 0.00e+00  2.05e-03     0s\n",
      "   7   1.37802126e-05  2.83398547e+00  5.91e-01 0.00e+00  1.15e-03     0s\n",
      "   8   7.75833541e-06  1.87992950e+00  2.68e-01 0.00e+00  6.03e-04     0s\n",
      "   9   3.77956068e-06  9.32650305e-01  5.03e-02 0.00e+00  1.86e-04     0s\n",
      "  10   3.23308730e-06  2.43897260e-01  1.93e-02 0.00e+00  4.39e-05     0s\n",
      "  11   2.82746033e-06  1.30657987e-02  1.11e-16 0.00e+00  2.16e-06     0s\n",
      "  12   3.08824774e-06  5.67098895e-04  1.25e-16 0.00e+00  9.34e-08     0s\n",
      "  13   3.68995337e-05  4.88102881e-04  9.71e-17 0.00e+00  7.47e-08     0s\n",
      "  14   6.45588266e-05  4.54374408e-04  9.71e-17 0.00e+00  6.45e-08     0s\n",
      "  15   8.25415362e-05  4.11085385e-04  7.63e-17 0.00e+00  5.44e-08     0s\n",
      "  16   8.46286350e-05  3.88151786e-04  9.71e-17 0.00e+00  5.02e-08     0s\n",
      "  17   1.13723752e-04  3.38123420e-04  6.94e-17 0.00e+00  3.71e-08     0s\n",
      "  18   1.41238600e-04  2.99629094e-04  1.25e-16 0.00e+00  2.62e-08     0s\n",
      "  19   1.48328632e-04  2.59961159e-04  9.71e-17 0.00e+00  1.85e-08     0s\n",
      "  20   1.56714826e-04  1.86783414e-04  5.00e-16 0.00e+00  4.98e-09     0s\n",
      "  21   1.62843273e-04  1.68742924e-04  9.30e-16 0.00e+00  9.77e-10     0s\n",
      "  22   1.65954783e-04  1.66064633e-04  2.80e-15 0.00e+00  1.82e-11     0s\n",
      "  23   1.65969069e-04  1.65969071e-04  1.70e-14 5.64e-17  1.79e-16     0s\n",
      "\n",
      "Barrier solved model in 23 iterations and 0.32 seconds (0.18 work units)\n",
      "Optimal objective 1.65969069e-04\n",
      "\n",
      "Optimal objective value: 0.00016596906944551886\n"
     ]
    }
   ],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "# Create a new model\n",
    "model = gp.Model(\"mcf\")\n",
    "\n",
    "# Add variables\n",
    "maxpid = 0\n",
    "for fromsw in range(numsw):\n",
    "    for tosw in range(numsw):\n",
    "        maxpid = max(maxpid,len(netpath[fromsw][tosw]))\n",
    "vararr = list()\n",
    "for fromsw in range(numsw):\n",
    "    vararr.append(list())\n",
    "    for tosw in range(numsw):\n",
    "        vararr[fromsw].append(list())\n",
    "        for pid in range(maxpid):\n",
    "            vararr[fromsw][tosw].append(None)\n",
    "for fromsw in range(numsw):\n",
    "    for tosw in range(numsw):\n",
    "        if traffic[fromsw][tosw] > 0:\n",
    "            for pid in range(len(netpath[fromsw][tosw])):\n",
    "                var = model.addVar(name=f\"{fromsw}_{tosw}_{pid}\")\n",
    "                vararr[fromsw][tosw][pid] = var\n",
    "k = model.addVar(name=\"k\")\n",
    "\n",
    "# Set objective function\n",
    "model.setObjective(k, GRB.MAXIMIZE)\n",
    "\n",
    "# Add constraints\n",
    "# Constraint 0: for each fid: sum(pid) >= k * traffic[fid.from][fid.to]\n",
    "for fromsw in range(numsw):\n",
    "    for tosw in range(numsw):\n",
    "        if traffic[fromsw][tosw] > 0:\n",
    "            varlist = list()\n",
    "            for pid in range(len(netpath[fromsw][tosw])):\n",
    "                varlist.append(vararr[fromsw][tosw][pid])\n",
    "            model.addConstr(sum(varlist)>=k*traffic[fromsw][tosw],f\"c0_{fromsw}_{tosw}\")\n",
    "\n",
    "# Constraint 1: for each link: sum(fid_pid) <= link[link.from][link.to]\n",
    "for linkfrom in range(numsw):\n",
    "    for linkto in range(numsw):\n",
    "        flowstrlist = flowsvialink[linkfrom][linkto]\n",
    "        if len(flowstrlist) > 0:\n",
    "            varlist = list()\n",
    "            for flowstr in flowstrlist:\n",
    "                tokens = flowstr.split(',')\n",
    "                flowfrom = int(tokens[0])\n",
    "                flowto = int(tokens[1])\n",
    "                pid = int(tokens[2])\n",
    "                varlist.append(vararr[flowfrom][flowto][pid])\n",
    "            model.addConstr(sum(varlist)<=link[linkfrom][linkto],f\"c1_{linkfrom}_{linkto}\")\n",
    "\n",
    "# Optimize model\n",
    "model.setParam('Method',method)\n",
    "model.setParam('Crossover',crossover)\n",
    "model.optimize()\n",
    "# model.write(modelfile)\n",
    "\n",
    "# Print results\n",
    "if model.status == GRB.OPTIMAL:\n",
    "    print(f\"Optimal objective value: {model.objVal}\")\n",
    "    with open(varfile,'w') as f:\n",
    "        f.write(f\"{k.varName},{k.x}\\n\")\n",
    "        for fromsw in range(numsw):\n",
    "            for tosw in range(numsw):\n",
    "                if traffic[fromsw][tosw] > 0:\n",
    "                    for pid in range(len(netpath[fromsw][tosw])):\n",
    "                        var = vararr[fromsw][tosw][pid]\n",
    "                        f.write(f\"{var.varName},{var.x}\\n\")\n",
    "else:\n",
    "    print(\"No optimal solution found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "quantize\n",
    "// inspired by https://github.com/AnnZhouCcc/PathWeightFileGenerator/blob/main/src/GenerateQuantizedPathWeightFromWeightTuningLpSolverUpdated.java\n",
    "inspired by chatgpt now\n",
    "two steps: 1. pair each number with its index 2. value to weight first 3. quantize to the nearest multiple of 1/64 4. adjust to ensure they add up to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "def quantize_to_multiple_of_1_64(x,factor):\n",
    "    return round(x * factor) / factor\n",
    "\n",
    "def quantize_and_adjust_with_indices(indexed_values,factor,isprint=False):\n",
    "    if isprint: print(indexed_values)\n",
    "    # Quantize each value\n",
    "    quantized_values = [(i, quantize_to_multiple_of_1_64(v,factor)) for i, v in indexed_values]\n",
    "    if isprint: print(quantized_values)\n",
    "    \n",
    "    # Calculate the current sum\n",
    "    current_sum = sum(v for _, v in quantized_values)\n",
    "    \n",
    "    # Calculate the difference between the sum and 1\n",
    "    difference = current_sum - 1\n",
    "    if isprint: print(f\"currsum={current_sum}, difference={difference}\")\n",
    "\n",
    "    random_values = [(v, random.random()) for v in quantized_values]\n",
    "    if isprint: print(random_values)\n",
    "    \n",
    "    if difference != 0:\n",
    "        if difference > 0:\n",
    "            # Sort indices by quantized values to adjust the largest values first\n",
    "            sorted_random = sorted(random_values, key=lambda x: (x[0][1],x[1]), reverse=True)\n",
    "            # sorted_quantized = sorted(quantized_values, key=lambda x: x[1], reverse=True)\n",
    "            sorted_quantized = [v for v,_ in sorted_random]\n",
    "            if isprint: print(sorted_random)\n",
    "            if isprint: print(sorted_quantized)\n",
    "            \n",
    "            while difference !=0:\n",
    "                for i, value in sorted_quantized:\n",
    "                    if difference == 0:\n",
    "                        break\n",
    "                    # Calculate adjustment\n",
    "                    # adjustment = min(difference, value % (1 / factor))\n",
    "                    # adjustment = difference\n",
    "                    new_value = value - 1.0/factor\n",
    "                    \n",
    "                    # Update the quantized values\n",
    "                    quantized_values = [(idx, new_value if idx == i else v) for idx, v in quantized_values]\n",
    "                    difference -= 1.0/factor\n",
    "                \n",
    "        else:\n",
    "            # If the difference is negative (i.e., sum is less than 1), we need to increase values\n",
    "            sorted_quantized = sorted(quantized_values, key=lambda x: x[1])\n",
    "            \n",
    "            while difference != 0:\n",
    "                for i, value in sorted_quantized:\n",
    "                    if difference == 0:\n",
    "                        break\n",
    "                    # Calculate adjustment\n",
    "                    # adjustment = min(-difference, (1 / factor) - (value % (1 / factor)))\n",
    "                    # adjustment = -difference\n",
    "                    new_value = value + 1.0/factor\n",
    "                    \n",
    "                    # Update the quantized values\n",
    "                    quantized_values = [(idx, new_value if idx == i else v) for idx, v in quantized_values]\n",
    "                    difference += 1.0/factor\n",
    "    \n",
    "    # Return the list sorted by original indices\n",
    "    # return [v for i, v in sorted(quantized_values)]\n",
    "    if isprint: print(quantized_values)\n",
    "    return quantized_values\n",
    "\n",
    "\n",
    "with open(varfile,'r') as f:\n",
    "    lines = f.readlines()[1:]\n",
    "\n",
    "valuearr = list()\n",
    "weightarr = list()\n",
    "qweightarr = list()\n",
    "for i in range(numsw):\n",
    "    valuearr.append(list())\n",
    "    weightarr.append(list())\n",
    "    qweightarr.append(list())\n",
    "    for j in range(numsw):\n",
    "        valuearr[i].append(list())\n",
    "        weightarr[i].append(list())\n",
    "        qweightarr[i].append(list()) \n",
    "\n",
    "for line in lines:\n",
    "    tokens = line.split(',')\n",
    "    varname = tokens[0]\n",
    "    vartokens = varname.split('_')\n",
    "    fromsw = int(vartokens[0])\n",
    "    tosw = int(vartokens[1])\n",
    "    pid = int(vartokens[2])\n",
    "    value = float(tokens[1])\n",
    "    valuearr[fromsw][tosw].append([pid,value])\n",
    "    weightarr[fromsw][tosw].append([pid,value])\n",
    "\n",
    "for fromsw in range(numsw):\n",
    "    for tosw in range(numsw):\n",
    "        if len(valuearr[fromsw][tosw])>0:\n",
    "            valuesum = 0\n",
    "            for _,value in valuearr[fromsw][tosw]:\n",
    "                valuesum += value\n",
    "            valuetoweight = 1.0/valuesum\n",
    "            for ipv,pv in enumerate(weightarr[fromsw][tosw]):\n",
    "                weightarr[fromsw][tosw][ipv][1] = pv[1] * valuetoweight\n",
    "\n",
    "for fromsw in range(numsw):\n",
    "    for tosw in range(numsw):\n",
    "        if len(weightarr[fromsw][tosw])>0:\n",
    "            qweightarr[fromsw][tosw] = quantize_and_adjust_with_indices(weightarr[fromsw][tosw],factor)\n",
    "\n",
    "with open(qvarfile,'w') as f:\n",
    "    for fromsw in range(numsw):\n",
    "        for tosw in range(numsw):\n",
    "            if len(qweightarr[fromsw][tosw])>0:\n",
    "                for pid,weight in qweightarr[fromsw][tosw]:\n",
    "                    if weight>0:\n",
    "                        f.write(f\"{fromsw},{tosw},{pid},{weight}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check qvarfile\n",
    "checkweightarr = list()\n",
    "for i in range(numsw):\n",
    "    checkweightarr.append(list())\n",
    "    for j in range(numsw):\n",
    "        checkweightarr[i].append(0)\n",
    "with open(qvarfile,'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        tokens = line.split(',')\n",
    "        fromsw = int(tokens[0])\n",
    "        tosw = int(tokens[1])\n",
    "        pid = int(tokens[2])\n",
    "        weight = float(tokens[3])\n",
    "        checkweightarr[fromsw][tosw] += weight\n",
    "\n",
    "for fromsw in range(numsw):\n",
    "    for tosw in range(numsw):\n",
    "        if checkweightarr[fromsw][tosw]!=0 and checkweightarr[fromsw][tosw]!=1:\n",
    "            print(f\"from {fromsw} to {tosw}: weight={checkweightarr[fromsw][tosw]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
