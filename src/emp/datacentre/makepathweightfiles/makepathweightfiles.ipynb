{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "solve\n",
    "inspired by https://github.com/AnnZhouCcc/topobench/blob/master/lpmaker/graphs/Graph.java#L1382"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "graphname = \"dring\"\n",
    "routingname = \"32disjoint\"\n",
    "pwname = \"\"\n",
    "numsw = 80\n",
    "numport = 64\n",
    "numserver = 2988\n",
    "numfaillink = 0\n",
    "numlink = 2132\n",
    "fseed = 0\n",
    "homedir = \"/home/annzhou\"\n",
    "\n",
    "c=64\n",
    "s=4\n",
    "multstr=\"2_7_8\"\n",
    "tseed = 0\n",
    "trafficname = f\"c2s_{c}_{s}_{tseed}_{multstr}\"\n",
    "\n",
    "method = 2\n",
    "crossover = 0\n",
    "factor = 64\n",
    "\n",
    "\n",
    "flowfile = f\"{homedir}/DRing/src/emp/datacentre/flowfiles/c2s_{c}_{s}_{multstr}_{tseed}\"\n",
    "\n",
    "if graphname==\"dring\" or graphname==\"rrg\":\n",
    "    netpathfile = f\"{homedir}/DRing/src/emp/datacentre/netpathfiles/netpath_{routingname}_{graphname}.txt\"\n",
    "else:\n",
    "    print(\"ERROR: leafspine does not need to compute path weight\")\n",
    "\n",
    "if graphname==\"dring\":\n",
    "    graphfile = f\"{homedir}/DRing/src/emp/datacentre/graphfiles/ring_supergraph/double_ring/instance1_{numsw}_{numport}.edgelist\"\n",
    "elif graphname==\"rrg\":\n",
    "    graphfile = f\"{homedir}/DRing/src/emp/datacentre/graphfiles/ring_supergraph/rrg/instance1_{numsw}_{numport}.edgelist\"\n",
    "else:\n",
    "    print(\"ERROR: leafspine does not need to compute path weight\")\n",
    "\n",
    "linkfailurefile = f\"{homedir}/DRing/src/emp/datacentre/linkfailurefiles/{graphname}_{numlink}_{numfaillink}_{fseed}\"\n",
    "\n",
    "serverfile = f\"{homedir}/DRing/src/emp/datacentre/serverfiles/{graphname}_{numserver}_{numsw}_{numport}\"\n",
    "\n",
    "tag = f\"{graphname}_{numfaillink}_{fseed}_{routingname}_{trafficname}_{method}_{crossover}_{factor}\"\n",
    "varfile = f\"{homedir}/DRing/src/emp/datacentre/qvarfiles/var_{tag}\"\n",
    "qvarfile = f\"{homedir}/DRing/src/emp/datacentre/qvarfiles/qvar_{tag}\"\n",
    "modelfile = f\"{homedir}/DRing/src/emp/datacentre/makepathweightfiles/model.lp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirprefix = f\"{homedir}/DRing/src/emp/datacentre\"\n",
    "# netpathfile = f\"{dirprefix}/netpathfiles/node3.txt\"\n",
    "# graphfile = f\"{dirprefix}/graphfiles/node3.edgelist\"\n",
    "# serverfile = f\"{dirprefix}/serverfiles/node3\"\n",
    "# flowfile = f\"{dirprefix}/flowfiles/node3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read netpathfile\n",
    "netpath = list()\n",
    "for i in range(numsw):\n",
    "    netpath.append(list())\n",
    "    for j in range(numsw):\n",
    "        netpath[i].append(list())\n",
    "with open(netpathfile,'r') as f:\n",
    "    lines = f.readlines()\n",
    "    # produce\n",
    "    fromsw = 0\n",
    "    tosw = 0\n",
    "    for line in lines:\n",
    "        if \"->\" not in line:\n",
    "            tokens = line.split()\n",
    "            fromsw = int(tokens[0])\n",
    "            tosw = int(tokens[1])\n",
    "        else:\n",
    "            path = [fromsw]\n",
    "            tokens = line.split()\n",
    "            for token in tokens:\n",
    "                hops = token.split(\"->\")\n",
    "                path.append(int(hops[1]))\n",
    "            netpath[fromsw][tosw].append(path)\n",
    "\n",
    "    # check\n",
    "    for line in lines:\n",
    "        if \"->\" not in line:\n",
    "            tokens = line.split()\n",
    "            fromsw = int(tokens[0])\n",
    "            tosw = int(tokens[1])\n",
    "            numpaths = int(tokens[2])\n",
    "            if len(netpath[fromsw][tosw])!=numpaths:\n",
    "                print(f\"ERROR: netpath is wrong, fromsw={fromsw}, tosw={tosw}, numpaths from file={numpaths}, numpaths from array={len(netpath[fromsw][tosw])}\")\n",
    "\n",
    "# read graphfile\n",
    "link = list()\n",
    "for i in range(numsw):\n",
    "    link.append(list())\n",
    "    for j in range(numsw):\n",
    "        link[i].append(0)\n",
    "with open(graphfile,'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        tokens = line.split(\"->\")\n",
    "        fromsw = int(tokens[0])\n",
    "        tosw = int(tokens[1])\n",
    "        link[fromsw][tosw] = 1\n",
    "        link[tosw][fromsw] = 1\n",
    "\n",
    "# read linkfailurefile (if needed)\n",
    "if numfaillink > 0:\n",
    "    with open(linkfailurefile,'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            tokens = line.split()\n",
    "            fromsw = int(tokens[0])\n",
    "            tosw = int(tokens[1])\n",
    "            if link[fromsw][tosw] != 1:\n",
    "                print(f\"ERROR: should have a link from {fromsw} to {tosw} but not\")\n",
    "            else:\n",
    "                link[fromsw][tosw] /= 2\n",
    "\n",
    "# read serverfile\n",
    "serverdict = dict()\n",
    "with open(serverfile,'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        tokens = line.split(',')\n",
    "        serverdict[int(tokens[0])] = int(tokens[1])\n",
    "\n",
    "# read flowfile\n",
    "traffic = list()\n",
    "for i in range(numsw):\n",
    "    traffic.append(list())\n",
    "    for j in range(numsw):\n",
    "        traffic[i].append(0)\n",
    "with open(flowfile,'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        tokens = line.split(\",\")\n",
    "        fromsvr = int(tokens[0])\n",
    "        tosvr = int(tokens[1])\n",
    "        if fromsvr>=numserver or tosvr>=numserver: continue\n",
    "        fromsw = serverdict[fromsvr]\n",
    "        tosw = serverdict[tosvr]\n",
    "        if fromsw == tosw: continue\n",
    "        flowbytes = int(tokens[2])\n",
    "        traffic[fromsw][tosw] += flowbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precompute\n",
    "flowsvialink = list()\n",
    "for i in range(numsw):\n",
    "    flowsvialink.append(list())\n",
    "    for j in range(numsw):\n",
    "        flowsvialink[i].append(list())\n",
    "for fromsw in range(numsw):\n",
    "    for tosw in range(numsw):\n",
    "        if traffic[fromsw][tosw] > 0:\n",
    "            for pid,path in enumerate(netpath[fromsw][tosw]):\n",
    "                fidpidstr = f\"{fromsw},{tosw},{pid}\"\n",
    "                prevhop = fromsw\n",
    "                for hop in path[1:]:\n",
    "                    flowsvialink[prevhop][hop].append(fidpidstr)\n",
    "                    prevhop = hop\n",
    "\n",
    "for fromsw in range(numsw):\n",
    "    for tosw in range(numsw):\n",
    "        traffic[fromsw][tosw] /= 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Method to value 2\n",
      "Set parameter Crossover to value 0\n",
      "Gurobi Optimizer version 11.0.3 build v11.0.3rc0 (linux64 - \"Ubuntu 20.04.6 LTS\")\n",
      "\n",
      "CPU model: Intel(R) Xeon(R) CPU E5-2630 v4 @ 2.20GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 20 physical cores, 40 logical processors, using up to 20 threads\n",
      "\n",
      "Optimize a model with 2764 rows, 16637 columns and 69492 nonzeros\n",
      "Model fingerprint: 0xe230e570\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+03]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+00, 1e+00]\n",
      "Presolve time: 0.04s\n",
      "Presolved: 2764 rows, 16637 columns, 69492 nonzeros\n",
      "Ordering time: 0.13s\n",
      "\n",
      "Barrier statistics:\n",
      " Dense cols : 1\n",
      " AA' NZ     : 7.803e+04\n",
      " Factor NZ  : 4.506e+05 (roughly 12 MB of memory)\n",
      " Factor Ops : 1.619e+08 (less than 1 second per iteration)\n",
      " Threads    : 20\n",
      "\n",
      "                  Objective                Residual\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\n",
      "   0   9.99071581e-03  4.81251264e-04  3.31e+02 7.27e-04  1.20e-01     0s\n",
      "   1   5.32875515e-05  4.21568543e+00  2.34e+02 2.52e-02  8.18e-02     0s\n",
      "   2   1.02049435e-03  4.70703105e+00  3.44e+01 5.63e-03  1.44e-02     0s\n",
      "   3   1.20396183e-04  2.31091793e+00  2.27e+00 4.51e-04  1.69e-03     0s\n",
      "   4   6.16087848e-05  5.04075362e-01  4.44e-15 8.65e-06  2.12e-04     0s\n",
      "   5   6.44858591e-05  1.13935485e-02  2.89e-15 1.83e-07  4.76e-06     0s\n",
      "   6   1.64625734e-04  4.57006287e-03  2.55e-15 0.00e+00  1.85e-06     0s\n",
      "   7   2.10617668e-04  1.53492633e-03  2.66e-15 0.00e+00  5.55e-07     0s\n",
      "   8   2.30627995e-04  5.15428451e-04  2.00e-15 0.00e+00  1.19e-07     0s\n",
      "   9   2.41703579e-04  3.01542656e-04  5.55e-15 0.00e+00  2.50e-08     0s\n",
      "  10   2.52099109e-04  2.57789930e-04  2.69e-14 1.13e-17  2.37e-09     0s\n",
      "  11   2.53778340e-04  2.53847090e-04  1.67e-13 4.20e-17  2.87e-11     0s\n",
      "  12   2.53780918e-04  2.53780987e-04  1.62e-11 4.07e-20  2.87e-14     0s\n",
      "\n",
      "Barrier solved model in 12 iterations and 0.37 seconds (0.19 work units)\n",
      "Optimal objective 2.53780918e-04\n",
      "\n",
      "Optimal objective value: 0.0002537809182403672\n"
     ]
    }
   ],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "# Create a new model\n",
    "model = gp.Model(\"mcf\")\n",
    "\n",
    "# Add variables\n",
    "maxpid = 0\n",
    "for fromsw in range(numsw):\n",
    "    for tosw in range(numsw):\n",
    "        maxpid = max(maxpid,len(netpath[fromsw][tosw]))\n",
    "vararr = list()\n",
    "for fromsw in range(numsw):\n",
    "    vararr.append(list())\n",
    "    for tosw in range(numsw):\n",
    "        vararr[fromsw].append(list())\n",
    "        for pid in range(maxpid):\n",
    "            vararr[fromsw][tosw].append(None)\n",
    "for fromsw in range(numsw):\n",
    "    for tosw in range(numsw):\n",
    "        if traffic[fromsw][tosw] > 0:\n",
    "            for pid in range(len(netpath[fromsw][tosw])):\n",
    "                var = model.addVar(name=f\"{fromsw}_{tosw}_{pid}\")\n",
    "                vararr[fromsw][tosw][pid] = var\n",
    "k = model.addVar(name=\"k\")\n",
    "\n",
    "# Set objective function\n",
    "model.setObjective(k, GRB.MAXIMIZE)\n",
    "\n",
    "# Add constraints\n",
    "# Constraint 0: for each fid: sum(pid) >= k * traffic[fid.from][fid.to]\n",
    "for fromsw in range(numsw):\n",
    "    for tosw in range(numsw):\n",
    "        if traffic[fromsw][tosw] > 0:\n",
    "            varlist = list()\n",
    "            for pid in range(len(netpath[fromsw][tosw])):\n",
    "                varlist.append(vararr[fromsw][tosw][pid])\n",
    "            model.addConstr(sum(varlist)>=k*traffic[fromsw][tosw],f\"c0_{fromsw}_{tosw}\")\n",
    "\n",
    "# Constraint 1: for each link: sum(fid_pid) <= link[link.from][link.to]\n",
    "for linkfrom in range(numsw):\n",
    "    for linkto in range(numsw):\n",
    "        flowstrlist = flowsvialink[linkfrom][linkto]\n",
    "        if len(flowstrlist) > 0:\n",
    "            varlist = list()\n",
    "            for flowstr in flowstrlist:\n",
    "                tokens = flowstr.split(',')\n",
    "                flowfrom = int(tokens[0])\n",
    "                flowto = int(tokens[1])\n",
    "                pid = int(tokens[2])\n",
    "                varlist.append(vararr[flowfrom][flowto][pid])\n",
    "            model.addConstr(sum(varlist)<=link[linkfrom][linkto],f\"c1_{linkfrom}_{linkto}\")\n",
    "\n",
    "# Optimize model\n",
    "model.setParam('Method',method)\n",
    "model.setParam('Crossover',crossover)\n",
    "model.optimize()\n",
    "# model.write(modelfile)\n",
    "\n",
    "# Print results\n",
    "if model.status == GRB.OPTIMAL:\n",
    "    print(f\"Optimal objective value: {model.objVal}\")\n",
    "    with open(varfile,'w') as f:\n",
    "        f.write(f\"{k.varName},{k.x}\\n\")\n",
    "        for fromsw in range(numsw):\n",
    "            for tosw in range(numsw):\n",
    "                if traffic[fromsw][tosw] > 0:\n",
    "                    for pid in range(len(netpath[fromsw][tosw])):\n",
    "                        var = vararr[fromsw][tosw][pid]\n",
    "                        f.write(f\"{var.varName},{var.x}\\n\")\n",
    "else:\n",
    "    print(\"No optimal solution found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "quantize\n",
    "// inspired by https://github.com/AnnZhouCcc/PathWeightFileGenerator/blob/main/src/GenerateQuantizedPathWeightFromWeightTuningLpSolverUpdated.java\n",
    "inspired by chatgpt now\n",
    "two steps: 1. pair each number with its index 2. value to weight first 3. quantize to the nearest multiple of 1/64 4. adjust to ensure they add up to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "def quantize_to_multiple_of_1_64(x,factor):\n",
    "    return round(x * factor) / factor\n",
    "\n",
    "def quantize_and_adjust_with_indices(indexed_values,factor,isprint=False):\n",
    "    if isprint: print(indexed_values)\n",
    "    # Quantize each value\n",
    "    quantized_values = [(i, quantize_to_multiple_of_1_64(v,factor)) for i, v in indexed_values]\n",
    "    if isprint: print(quantized_values)\n",
    "    \n",
    "    # Calculate the current sum\n",
    "    current_sum = sum(v for _, v in quantized_values)\n",
    "    \n",
    "    # Calculate the difference between the sum and 1\n",
    "    difference = current_sum - 1\n",
    "    if isprint: print(f\"currsum={current_sum}, difference={difference}\")\n",
    "\n",
    "    random_values = [(v, random.random()) for v in quantized_values]\n",
    "    if isprint: print(random_values)\n",
    "    \n",
    "    if difference != 0:\n",
    "        if difference > 0:\n",
    "            # Sort indices by quantized values to adjust the largest values first\n",
    "            sorted_random = sorted(random_values, key=lambda x: (x[0][1],x[1]), reverse=True)\n",
    "            # sorted_quantized = sorted(quantized_values, key=lambda x: x[1], reverse=True)\n",
    "            sorted_quantized = [v for v,_ in sorted_random]\n",
    "            if isprint: print(sorted_random)\n",
    "            if isprint: print(sorted_quantized)\n",
    "            \n",
    "            while difference !=0:\n",
    "                for i, value in sorted_quantized:\n",
    "                    if difference == 0:\n",
    "                        break\n",
    "                    # Calculate adjustment\n",
    "                    # adjustment = min(difference, value % (1 / factor))\n",
    "                    # adjustment = difference\n",
    "                    new_value = value - 1.0/factor\n",
    "                    \n",
    "                    # Update the quantized values\n",
    "                    quantized_values = [(idx, new_value if idx == i else v) for idx, v in quantized_values]\n",
    "                    difference -= 1.0/factor\n",
    "                \n",
    "        else:\n",
    "            # If the difference is negative (i.e., sum is less than 1), we need to increase values\n",
    "            sorted_quantized = sorted(quantized_values, key=lambda x: x[1])\n",
    "            \n",
    "            while difference != 0:\n",
    "                for i, value in sorted_quantized:\n",
    "                    if difference == 0:\n",
    "                        break\n",
    "                    # Calculate adjustment\n",
    "                    # adjustment = min(-difference, (1 / factor) - (value % (1 / factor)))\n",
    "                    # adjustment = -difference\n",
    "                    new_value = value + 1.0/factor\n",
    "                    \n",
    "                    # Update the quantized values\n",
    "                    quantized_values = [(idx, new_value if idx == i else v) for idx, v in quantized_values]\n",
    "                    difference += 1.0/factor\n",
    "    \n",
    "    # Return the list sorted by original indices\n",
    "    # return [v for i, v in sorted(quantized_values)]\n",
    "    if isprint: print(quantized_values)\n",
    "    return quantized_values\n",
    "\n",
    "\n",
    "with open(varfile,'r') as f:\n",
    "    lines = f.readlines()[1:]\n",
    "\n",
    "valuearr = list()\n",
    "weightarr = list()\n",
    "qweightarr = list()\n",
    "for i in range(numsw):\n",
    "    valuearr.append(list())\n",
    "    weightarr.append(list())\n",
    "    qweightarr.append(list())\n",
    "    for j in range(numsw):\n",
    "        valuearr[i].append(list())\n",
    "        weightarr[i].append(list())\n",
    "        qweightarr[i].append(list()) \n",
    "\n",
    "for line in lines:\n",
    "    tokens = line.split(',')\n",
    "    varname = tokens[0]\n",
    "    vartokens = varname.split('_')\n",
    "    fromsw = int(vartokens[0])\n",
    "    tosw = int(vartokens[1])\n",
    "    pid = int(vartokens[2])\n",
    "    value = float(tokens[1])\n",
    "    valuearr[fromsw][tosw].append([pid,value])\n",
    "    weightarr[fromsw][tosw].append([pid,value])\n",
    "\n",
    "for fromsw in range(numsw):\n",
    "    for tosw in range(numsw):\n",
    "        if len(valuearr[fromsw][tosw])>0:\n",
    "            valuesum = 0\n",
    "            for _,value in valuearr[fromsw][tosw]:\n",
    "                valuesum += value\n",
    "            valuetoweight = 1.0/valuesum\n",
    "            for ipv,pv in enumerate(weightarr[fromsw][tosw]):\n",
    "                weightarr[fromsw][tosw][ipv][1] = pv[1] * valuetoweight\n",
    "\n",
    "for fromsw in range(numsw):\n",
    "    for tosw in range(numsw):\n",
    "        if len(weightarr[fromsw][tosw])>0:\n",
    "            qweightarr[fromsw][tosw] = quantize_and_adjust_with_indices(weightarr[fromsw][tosw],factor)\n",
    "\n",
    "with open(qvarfile,'w') as f:\n",
    "    for fromsw in range(numsw):\n",
    "        for tosw in range(numsw):\n",
    "            if len(qweightarr[fromsw][tosw])>0:\n",
    "                for pid,weight in qweightarr[fromsw][tosw]:\n",
    "                    if weight>0:\n",
    "                        f.write(f\"{fromsw},{tosw},{pid},{weight}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check qvarfile\n",
    "checkweightarr = list()\n",
    "for i in range(numsw):\n",
    "    checkweightarr.append(list())\n",
    "    for j in range(numsw):\n",
    "        checkweightarr[i].append(0)\n",
    "with open(qvarfile,'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        tokens = line.split(',')\n",
    "        fromsw = int(tokens[0])\n",
    "        tosw = int(tokens[1])\n",
    "        pid = int(tokens[2])\n",
    "        weight = float(tokens[3])\n",
    "        checkweightarr[fromsw][tosw] += weight\n",
    "\n",
    "for fromsw in range(numsw):\n",
    "    for tosw in range(numsw):\n",
    "        if checkweightarr[fromsw][tosw]!=0 and checkweightarr[fromsw][tosw]!=1:\n",
    "            print(f\"from {fromsw} to {tosw}: weight={checkweightarr[fromsw][tosw]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
